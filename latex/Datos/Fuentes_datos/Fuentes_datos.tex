
\chapter{Fuentes principales de datos espaciales}
\label{Fuentes_datos}




No hace tanto tiempo, toda la información que se manejaba dentro de un SIG tenía su origen en un mapa en papel, el cual debía \emph{prepararse} para adaptarse a la naturaleza propia del SIG. El dato geográfico se obtenía a partir de la \textbf{digitalización} de cartografía, es decir, convertir los datos geográficos en formato impreso en datos en formato digital que un SIG pudiera manejar. 

Un SIG implica una aplicación informática, y esta se alimenta en última instancia exclusivamente de datos digitales. Los datos geográficos digitales tienen una serie de ventajas frente a los analógicos (además del mero hecho de que podemos incorporarlos a nuestro SIG), y suponen, como sucede en muchos otros campos, un salto cualitativo importante. Entre estas ventajas, que son a su vez comunes a otros ámbitos,  destacan la sencillez de actualización, la facilidad de distribución (en especial con la aparición de Internet), el menor espacio físico necesario para su almacenamiento, la facilidad y precisión del análisis, y la facilidad de mantenimiento (el dato digital no se degrada, lo que se degrada es su soporte, pero es sencillo replicar el dato sin pérdida de calidad)

Hoy en día las técnicas de adquisición de datos han evolucionado y permiten crear datos que pueden ser directamente integrados en un SIG. Distinguimos así \textbf{fuentes de datos primarias} y \textbf{secundarias}. 

Las fuentes de datos primarias son aquellas cuyos datos podemos emplear en un SIG, ya que estos, en su forma original, ya son susceptibles de ser sometidos a las operaciones de manejo y análisis que incorporan los SIG. Por su parte, las fuentes de datos secundarias generan datos que no pueden emplearse en un SIG sin un proceso de adaptación previo, siendo el dato derivado el que utilizamos en un SIG, no el original. 

En este capítulo, veremos las distintas fuentes de datos con las que podemos trabajar un en SIG.


\section{Teledetección}\index{Teledetección}

La primera fuente de datos que trataremos en este capítulo es la teledetección. Entendemos por teledetección el estudio y medida de las características de una serie de objetos (en nuestro caso elementos de la superficie terrestre) sin que exista contacto físico. Para ello, se miden las perturbaciones que el objeto provoca en su entorno, principalmente las de tipo electromagnético.

Un sistema de teledetección cuenta con los siguientes elementos (Figura \ref{Fig:Elementos_teledeteccion}):

\begin{figure}[!hbt]   
\centering
\includegraphics[width=.4\textwidth]{Fuentes_datos/Elementos_teledeteccion.pdf}
\caption{\small Esquema de un sistema de teledetección.}
\label{Fig:Elementos_teledeteccion} 
\end{figure}


\begin{itemize}
	\item \textbf{Una fuente de radiación (A)}\index{Fuente de radiación}. Puede ser de origen natural o artificial. La radiación emitida por dicha fuente llega al terreno y sufre una perturbación causada por los elementos de este, siendo esta perturbación el objeto de estudio de la teledetección. Los propios objetos pueden ser también emisores ellos mismos de radiación.
	\item \textbf{Unos objetos (B) que interaccionan con la radiación} o la emiten, según lo anterior.
	\item \textbf{Una atmósfera (C)} por la que se desplaza la radiación, tanto desde la fuente hasta el objeto como desde el objeto hasta el receptor. La atmósfera también interactúa con la radiación, introduciendo igualmente perturbaciones en ella.
	\item \textbf{Un receptor (D) que recoge la radiación} una vez esta ha sido perturbada o emitida por los objetos. El receptor va a generar como producto final una imagen (en términos de un SIG, una capa ráster), en cuyas celdas o píxeles se va a contener un valor que indica la intensidad de la radiación. Estos valores son valores enteros que indican el nivel de dicha radiación dentro de una escala definida (habitualmente valores entre 1 y 256), y se conocen dentro del ámbito de la teledetección como \textbf{Niveles Digitales}.
\end{itemize}

A lo largo de este apartado veremos con detalle estos elementos. Para estudiar los dos primeros, estudiaremos los fundamentos físicos relativos a la radiación y a la la interacción entre esta y la materia, mientras que para el estudio del sistema receptor analizaremos los elementos de este en dos componentes por separado: sensores y plataformas. 

La interacción de la atmósfera interesa de cara a eliminar su efecto, ya que lo que resulta de interés en general son los objetos en la superficie terrestre, no la atmósfera como tal. Eliminar esta influencia de la atmósfera es parte de los procesos posteriores que se realizan con la imagen, y que se detallan en los capítulos dedicados al análisis de imágenes en lugar de en este.

\subsection{Fundamentos físicos}

La radiación electromagnética es producto de las alteraciones en los campos eléctrico y magnético, las cuales generan ondas correspondientes a cada uno de los campos magnético y eléctrico. Estas ondas se desplazan a la velocidad de la luz, y se pueden describir con los parámetros habituales, tales como la longitud de onda o la frecuencia. El rango de longitudes de onda cubierta por la radiación electromagnética se conoce como \textbf{espectro electromagnético}.

El espectro se subdivide en regiones en función de su longitud de onda, tales como (de menor a mayor longitud de onda) los rayos $\gamma$, los rayos X, la región ultravioleta, la región visible, la región infraroja, o las microondas  

La radiación emitida por una fuente de radiación es alterada por la presencia de los distintos objetos, ya que estos \textbf{absorben, transmiten} o \textbf{reflejan} esta.

Estos tres fenómenos se dan en diferente proporción en función de las características del objeto y de la radiación. La parte que  interesa a efectos de la teledetección es aquella que se refleja en el objeto, ya que esta es la que posteriormente puede recogerse y emplearse para la generación de las imágenes.

Como ya se dijo en el capítulo \ref{Introduccion_datos}, las imágenes como capas ráster presentan habitualmente la particularidad de tener varias bandas. En lugar de un único valor para cada celda, existen $n$ valores, uno por cada banda. La imagen recoge la intensidad de la radiación dentro de una amplitud dada del espectro, y a su vez subdivide esta en distintas franjas. Los Niveles Digitales de cada banda corresponden a la intensidad dentro de una de esas franjas del espectro en particular.

Puesto que cada objeto refleja la radiación de diferentes longitudes de onda de modo distinto, esto puede considerarse como una propiedad del objeto. Se tiene así el concepto de \textbf{firma espectral}, que es la respuesta característica de un tipo de objeto dentro del espectro electromagnético. 


\subsection{Sensores y plataformas}

En un sistema de teledetección, dos son los elementos tecnológicos principales que lo definen: el \textbf{sensor} y la \textbf{plataforma}. 

El sensor es el elemento que incorpora la capacidad de <<leer>> la radiación electromagnética y registrar su intensidad dentro de la una zona concreta del espectro. Puede ir desde una simple cámara fotográfica hasta un sensor más especializado.

Los sensores se denominan \textbf{pasivos} aprovechan las fuentes de radiación existentes en la naturaleza (fundamentalmente el Sol) y se limitan a recoger la radiación de dichas fuentes reflejada por los elementos del medio, o \textbf{activos} sí emiten radiación, y recogen dicha radiación tras ser reflejada por dichos elementos. Para entender este concepto de un modo de un modo sencillo, podemos decir que una cámara fotográfica es un sensor pasivo, mientras que una camara fotográfica con \emph{flash} es un sensor activo. La radiación emitida por los sensores activos no ha de ser necesariamente luz visible (como en el caso del flash), sino que pueden emitir en otras secciones del espectro.

Tecnologías como el \textbf{radar} o el \textbf{LiDAR} (similar al radar pero con pulsos de laser en lugar de ondas de radio), se basan en sensores activos. En el caso del LiDAR, permite obtener imagenes que no tiene un caracter visual, sino que contienen en sus valores la elevación de los objetos, pudiendo así emplearse para cartografiar el relieve.


La plataforma, por su parte, es el medio en el que se sitúa el sensor y desde el cual se realiza la observación.  A bordo de una plataforma pueden montarse varios sensores.

Los dos tipos principales de plataformas son aquellas situadas \textbf{{dentro de la atmósfera} terrestre (aviones en su mayoría) y aquellas situadas \textbf{fuera de la atmósfera} (a bordo de satélites).

Los aviones tienen la ventaja de su \texbtf{disponibilidad}, ya que pueden pilotarse y de este modo permiten cubrir cualquier lugar de la tierra en cualquier momento.

A diferencia de un avión, un satélite no puede dirigirse a voluntad (no puede pilotarse), y su movimiento es una característica inherente que viene definida por una serie de parámetros. Estos parámetros se conocen como \textbf{{parámetros orbitales} pues definen la órbita descrita por el satélite en torno a la Tierra. 

Las órbitas pueden clasificarse en función de su eje de rotación así como en función de su movimientos. En este último caso tenemos órbitas \textbf{geosíncronas} (el satélite se sitúa sobre un punto fijo de la Tierra y su movimiento sigue al de rotación de esta) o \textbf{heliosíncronas} (mientras el satélite recorre la órbita, la Tierra efectúa su movimiento de rotación, lo cual hace que a cada vuelta de la órbita se cubran zonas distintas) 
	
	

\subsubsection{Resoluciones}

Uno de los parámetros principales que definen las propiedades de un sistema de teledetección son las \emph{resoluciones}. Estas establecen el nivel de detalle de los productos que el sistema genera, determinando este en las distintas magnitudes en las que el sistema opera. Las resoluciones dependen del sensor y de la plataforma como binomio operativo, y de las características propias de ambos. Distinguimos cuatro resoluciones, a saber:

\begin{itemize}
	\item \textbf{Resolución espacial}. Indica la dimensión del objeto más pequeño que puede distinguirse en la imagen. Es la dimensión real que un píxel de la imagen tiene sobre el terreno.

	
	\item \textbf{Resolución espectral}. Indica la amplitud de cada una de las regiones del espectro quqe se recogen en la imagen. La región del espectro abarcada y el número de bandas son los elementos que definen la resolución espectral. 

	\item \textbf{Resolución radiométrica}. Para cada una de las bandas que produce un sensor (asociada esta a una determinada región del espectro según su resolución espectral), el dato recogido, que constituye su Nivel Digital, indica la intensidad correspondiente a esa región. El nivel de detalle con el que puede medirse esa intensidad es el que define la resolución radiométrica del sensor.\index{Resolución!radiométrica}
	
	\item \textbf{Resolución temporal}. Indica el tiempo que tarda el sensor en volver a tomar una imagen de una misma zona.  Tiene sentido en el caso de sensores orbitales. La resolución temporal depende de la altura a la que se encuentra la plataforma que monta el sensor, así como la resolución espacial. 
\end{itemize}

No resulta posible (por razones técnicas y teóricas) disponer de un sensor en el cual todas las anteriores regiones sean altas. Algunos sensores priman determinadas resoluciones, mientras que otros favorecen otras distintas.

A la hora de utilizar imágenes de teledetección, debe considerarse qué tipo de resolución  resulta de mayor interés (por ejemplo, para localizar elementos de pequeño tamaño son necesarias imágenes con alta resolución especial). En base a esto, se escogerá una u otra clase de imágenes, que será la que ofrezca los valores de resolución más adecuados en conjunto. La utilización simultánea de datos de varios sensores en un proyecto es una alternativa para compensar este hecho.


\subsection{Fotogrametría}
\label{Fotogrametria}

\index{Fotogrametría}

Relacionada con la teledetección, encontramos la \textbf{fotogrametría}. La fotogrametría es la técnica para estudiar y definir con precisión la forma, dimensiones y posición en el espacio de un objeto cualquiera, utilizando medidas realizadas sobre una o varias fotografías. En el campo del SIG, es de especial interés la \textbf{fotogrametría aérea}, cuya base de trabajo tradicional son las fotografías aéreas, y que sirve principalmente para la creación de cartografía de elevaciones a partir de un proceso de \textbf{restitución}.

En lugar de imágenes individuales, la fotogrametría emplea pares de imágenes, cada una de ellas tomada desde un punto distinto. Mediate estereoscopía, resulta posible recrear el efecto que ambas imágenes tendrían para la reconstrucción tridimensional de la escena, y <<engañar>> al cerebro del observador para que este pueda observar la escena con volumen y profundidad. Esto permite posteriormente conocer las formas del terreno, y a partir de ello crear las capas correspondientes, con informacion de elevaciones.

Cuando se emplean imágenes de satélite, los pares se pueden obtener con aquellas plataformas y sensores que permiten variar el ángulo de visión, de modo que en la misma pasada del satélite se toman imágenes de una zona desde distintos puntos. 

Según su enfoque, la fotogrametría puede ser \textbf{analógica}, \textbf{analítica} o  \textbf{digital}, siendo esta última la que se basa en el trabajo con imágenes digitales dentro de un entorno computerizado, y la que mayor relación tiene con los SIG. 

La fotogrametría requiere de una \emph{estación fotogramétrica}, que en el caso digital incorpora muchos elementos propios de un SIG, así como otros específicos del trabajo fotogramétrico. Entre estos, caben destacar aquellos que permiten la generación de visualizaciones con sensación de profundidad, así como los periféricos específicos tales como ratones 3D o manivelas similares a las que presentan los restituidores analíticos, facilitando así la adaptación de los operarios a este tipo de estación.


\section{Cartografía impresa. Digitalización}

Existe gran cantidad de cartografía en formato no digital, tales como mapas impresos o fotografías aéreas antiguas en formato analógico. 

La \textbf{digitalización} de esta cartografía, necesaria para su uso en un SIG, supone la creacion de capas raster o vectoriales a partir de ella. En este último caso, implica la \textbf{disgregación} de la información que contiene, ya que en un mapa clasico se presentan distintas informaciones que en el uso común de un SIG se almacenan en capas independientes.

La digitalización implica tres etapas: el \textbf{registro o georeferenciación}(Establecimiento del marco geográfico ---sistema de coordenadas, puntos de control, etc---, de forma que los elementos digitalizados posteriormente sean correctos), la digitalización de la compoente espacial (creación de geometrías en el caso de capas vectoriales), y la digitalización de la componente temática (creación de valores de celda en el caso de capas raster o de atributos en el caso vectorial).

La digitalización puede ser \textbf{manual} o \textbf{automática}. En el primer caso, es un operario quien introduce los valores de los elementos digitalizados, mientras que en el segundo caso es un procedimiento automatizado el que se encarga de ello.

Para la creación de capas raster, lo habitual es la digitalización automática, a partir del \textbf{escaneo} del documento original.

El escaneo es el proceso de digitalización que convierte una imagen impresa (analógica) en una imagen digital. Dentro de un SIG, se emplea para digitalizar tanto mapas como fotografías aéreas, y su resultado es una capa ráster. 

Aunque existen escáneres específicamente diseñados para el trabajo con documentos cartográficos, estos son dispositivos muy especializados y de muy elevado coste. Los escáneres más genéricos, pensados para el trabajo con todo tipo de imágenes y para todo tipo de usos, pueden no obstante emplearse de igual modo para escanear tanto mapas como imágenes aéreas con resultados aceptables, utilizándose con frecuencia.


Los parámetros básicos que definen las características de un escáner son la resolución espacial y la resolución radiométrica. La primera de estas de mide habitualmente en \textbf{puntos por pulgada} y nos indica el número de puntos (celdas) que el sensor es capaz de tomar por cada unidad de longitud sobre el papel. La resolución radiométrica, por su parte, indica la capacidad del sensor para distinguir entre dos colores distintos. 

En relación con las resoluciones de escaneo, no deben olvidarse los fundamentos cartográficos que se explicaron en el capítulo \ref{Fundamentos_cartograficos}. Trabajando con una resolución más elevada no hace necesariamente que estemos incorporando más información, ya que esta puede no existir en el documento original. Tendríamos un volumen de datos más elevado que el necesario para recoger toda la información del mapa.

En el caso de capas vectoriales, es más habitual la digitalización manual. En ella, un operario va definiendo las entidades, trazando las forma de estas o, en caso de ser una entidad de tipo punto, indicando su localización. 

Para llevar a cabo ese trazado de la entidad, se necesita emplear algún equipo que recoja la información introducida por el operador. Existen dos alternativas principales: utilizar una \textbf{tableta digitalizadora} diseñada específicamente para la digitalización, o bien digitalizar utilizando las \textbf{funciones de edición} de un SIG, realizando todo el proceso dentro de este y sin más herramientas que el propio ordenador y un dispositivo señalador como el ratón. En este segundo caso, la digitalización se produce sobre la pantalla, por lo que es necesario tener ya una versión  digital del documento (aunque no en forma de capa vectorial), la cual puede obtenerse mediante escaneo.

La digitalización automática de entidades para formar una capa vectorial, conocida como \textbf{vectorización}, resulta también posible, aunque presenta más dificultades. El principal problema reside en la necesidad de preparar adecuadamente el documento a digitalizar, ya que las condiciones de este afectan notablemente a la calidad del resultado. La vectorización, al igual que la digitalización manual, puede llevarse a cabo mediante dispositivos especializados, o bien mediante el software apropiado, el cual se ejecuta en un ordenador y trabaja con una imagen escaneada del documento original.

Un caso particular de digitalización es la creación de capas a partir de valores o coordenadas. Es decir, cuando no existe un mapa o documento cartográfico, sino simplemente una serie de datos espaciales expresados de forma alfanumérica que son susceptibles de convertirse en una capa y emplearse así dentro de un SIG.

Este proceso se conoce como \textbf{geocodificación}  e implica la asignación de coordenadas a puntos de interés tales como muestreos de campo levantamientos topográficos, inventarios de lugares donde tiene lugar un determinado fenómeno  o existe un determinado elemento, u otros como el \emph{geotagging} de fotografías, para asociar a estas la posición del enclave en el que se han tomado.

En el caso de encontrarse en formato analógico, estos datos pueden digitalizarse mediante la simple introducción manual de coordenadas a través del teclado o bien mediante algún sistema más específico como el escaneo del documento y el empleo de algún software de reconocimiento de caracteres (OCR).

En el caso de encontrarse ya en formato digital, estos datos pueden presentarse como tablas en una hoja de cálculo, datos asociados a otro dato de cualquier tipo (como en el caso del \emph{geotagging}) o incluso simples archivo de texto. Muchos SIG incorporan métodos para leer estos archivos y después utilizar las coordenadas que contienen con el fin de crear una nueva capa, en general de puntos.



\subsection{Calidad de la digitalización}
\label{Condiciones_digitalizacion}

\index{Digitalización!calidad}

Uno de los aspectos más importantes del proceso de digitalización es la calidad del resultado obtenido, que debe tratar de ser lo más cercano posible a la calidad original de la información que se digitaliza, es decir, del mapa o imagen original. Independientemente de la precisión del equipo utilizado o la habilidad y experiencia del operario, la digitalización no es por completo perfecta, conteniendo siempre ciertas deficiencias y errores. 

Además de los errores que puedan incorporarse en las distintas fases del proceso de digitalización (sea este del tipo que sea), hay que considerar que las fuentes originales a digitalizar también pueden incluir los suyos propios. Así, el proceso de escaneado puede incorporar distorsiones geométricas, pero es posible que el mapa o fotografía aérea de partida también presente alguna distorsión como consecuencia de su deterioro, más patente cuanto más antigua sea esta. 

La información contenida en el documento cartográfico puede también contener elementos problemáticos de cara a obtener un producto de calidad, que pueden ir desde líneas borradas total o parcialmente a manchas en el propio mapa derivadas de su uso habitual.

Dentro de los errores que aparecen como consecuencia de la digitalización en sí, un tipo importante de ellos son las discrepancias y coincidencias imperfectas entre las distintas entidades, tal como las que se muestran en la figura \ref{Fig:Imprecisiones_digitalizacion}

\begin{figure}[!hbt]   
\centering
\includegraphics[width=.8\textwidth]{Fuentes_datos/Imprecisiones_digitalizacion.pdf}
\caption{\small Errores derivados del proceso de digitalización. a) Versión correcta, con nodos coincidentes. b) y c) Versiones con errores que causan una falsa desconexión entre las líneas.}
\label{Fig:Imprecisiones_digitalizacion} 
\end{figure}


Debido a esto, las capacidades de edición de los SIG incorporan funcionalidades que permiten evitar estos errores en el momento de la digitalización, ayudando al operario en su tarea y permitiéndole alcanzar una exactitud y precisión imposible de lograr sin estas funcionalidades. Entre ellas, es especialmente importante el establecimiento de tolerancias y ajuste automático en función de ellas (esto se conoce con el término ingles \textbf{snapping}), que ayudan a garantizar la coincidencia entre los distintos vértices. 


El hecho de que exista una completa coincidencia es especialmente importante cuando la capa vectorial que se digitaliza contiene información topológica. La topología exige que la coincidencia sea correcta y defina perfectamente la relación entre las entidades. La digitalización de entidades, en caso de querer recoger su topología, debe realizarse siguiendo reglas adicionales tales como la digitalización una única vez de los lados comunes de polígonos. Debe, asimismo, recoger información adicional, como por ejemplo la necesaria para la definición de nodos en los cruces entre líneas cuando existe relación entre estas.


\section{GPS}
\label{GPS}

Uno de los hitos en la aparición de nuevas fuentes de datos geográficos es la aparición de los \emph{Sistemas Globales de Navegación por Satélite}. Un GNSS es un sistema que permite conocer en todo momento y en cualquier punto del globo la localización exacta de dicho punto con un margen de error del orden de unos pocos metros o menos. Para ello, se basan en el envío de señales entre un dispositivo situado en el punto concreto y una red de satélites, pudiendo establecerse la posición exacta mediante las características de dicha transmisión.

El ejemplo más extendido de un GNSS es el \textbf{Sistema de Posicionamiento Global} (Global Positioning System, o \textbf{GPS}). El GPS cuenta con una constelacion de 24 satélites activos, así como estaciones terrestres que los controlan, y su funcionamiento se basa en la triangulación de la posición de una unidad receptora, mediante las señales procedentes de un cierto número de satélites. Esta triangulación se basa en distancias entre la unidad receptora y dichos satelites, las cuales se calculan mediante diversos mecanismos. La posición se calcula no únicamente en sus coordenadas \emph{x} e \emph{y}, sino también en \emph{z}, es decir en elevación. El sistema GPS emplea como sistema geodésico de referencia el WGS84.

.



El diseño de la red de satélites está pensado para garantizar que en cualquier punto de la superficie terrestre y en cualquier momento, un receptor puede localizar el número necesario de satélites para obtener con exactitud su precisión. 

Existen numerosas fuentes de error que causa desviaciones apreciables en el calculo de coordenadas mediante GPS. Entre ellas destacan los errores en la posición de los satélites, errores por el rebote de la señal en otros con anterioridad a alcanzar el receptor, errores por el paso de la señal por la atmósfera, así como los de precisión de los relojes empleados para el cálculo de distancias. La \textbf{disponibilidad selectiva} era un error aleatorio introducido en la señal GPS con fines militares, pero fue eliminada en el año 2000.

Entre las técnicas empleadas para corregir estas desviaciones, destaca el denominado \emph{GPS diferencial}, pensado en origen para eliminar el error de la disponibilidad selectiva, aunque también eficaz para corregir una buena parte los restantes errores citados anteriormente.

Para la aplicación del GPS diferencial se requiere no solo un receptor único (aquel del cual se quiere calcular su posición), sino también otro receptor fijo de referencia cuyas coordenadas se conocen con alta precisión. Este receptor fijo es, a su vez, un receptor de alta precisión y, además de calcular su propia posición, emite información que las unidades receptoras pueden aprovechar para corregir sus mediciones. El receptor móvil, lógicamente, tiene que soportar este tipo de correcciones, para poder hacer uso de la señal de la estación de referencia.

El fundamento de esta técnica es que los errores que afectan al receptor móvil también afectan al de referencia. No obstante, la magnitud del error que afecta al receptor de referencia puede conocerse, ya que se conoce la coordenada exacta de este, y en base a eso puede eliminarse el error que afecta al receptor móvil, asumiendo que ambos errores son de similar índole.

En la actualidad, aplicando estas técnicas de corrección diferencial, un GPS puede obtener precisiones del orden de 2 metros en latitud y longitud, y 3 en altitud\cite{wikipediaGPS}. Sin corrección diferencial, esta precisión es de unos 10--20 metros.


La precisión del sistema GPS depende del tipo de receptor GPS (o, en el lenguaje común, GPS a secas) que se emplee, obteniéndose mayores precisiones con receptores más avanzados, siempre dentro de las posibilidades del propio sistema GPS. Existen muchas clases de receptores GPS, siendo dos de ellas las principales en relación con los SIG:
\begin{itemize}
	\item GPS para uso general. Unidades pequeñas y portátiles, de bajo coste, para actividades al aire libre, donde no se requiere una precisión elevada sino simplemente un conocimiento de la posición aproximada. Se emplean, por ejemplo, para recoger rutas en senderismo o navegación. 
	\item GPS para la medición topográfica. Unidades de medio tamaño, generalmente con una antena independiente que se conecta a la unidad y que el propio operario carga a la espalda. La antena garantiza mayor precisión y una mejor localización de satélites en condiciones tales como zonas bajo arbolado. Están pensados para un uso profesional en levantamientos o replanteos, ofreciendo buena precisión en todas las coordenadas. 
	
	


La capacidad principal de una unidad GPS en relación con un SIG es la de recoger coordenadas. Esta funcionalidad permite almacenar puntos o trazados completos, encontrándose el operario inmóvil o bien en movimiento a lo largo de dicho trazado. Es habitual utilizar los vocablos ingleses de la terminología GPS para denotar los distintos elementos que pueden recogerse, conociéndose a un punto de interés aislado como \textbf{waypoint} y un trazado como \textbf{track}. Una serie ordenada de \emph{waypoints} se conoce como \textbf{route} (ruta).

En el trabajo con el receptor GPS, el operario se puede detener en un punto cualquiera y memorizar las coordenadas del mismo, añadiendo así un \emph{waypoint} a la lista de los ya almacenados. Para crear un trazado, se suele disponer de funcionalidades de recogida automática de puntos, de tal modo que el receptor memoriza estos a intervalos fijos de tiempo. El operario simplemente ha de desplazarse por el trazado y dejar que el receptor haga su trabajo mientras tanto. 


\section{Información Geográfica Voluntaria}
\label{VGI}

Hemos mencionado ya que los dispositivos tales como receptores GPS de bajo coste pueden emplearse para recoger información geográfica y crear datos geográficos, y que cuando esto se une a los conceptos participativos de la denominada Web 2.0, surgen iniciativas de gran interés en las que el usuario de a pie, sin necesidad de una formación específica como cartógrafo, puede aportar sus datos para que otros los exploten posteriormente. Aunque no se trata de una fuente de datos como tal, y los elementos y dispositivos empleados ya los hemos visto a lo largo de este capítulo, el cambio que supone la inclusión de una filosofía acorde con las ideas de la Web 2.0 es tan notable que merece ser tratado por separado. No se trata de un cambio en la propia toma o preparación de datos, o de una tecnología nueva que se aplique a estos, sino de un cambio social y filosófico que redefine el propio concepto de la información geográfica en lo que a la creación del dato geográfico respecta, y cuyas consecuencias son ciertamente importantes, ya que abren el ámbito de la creación cartográfica a un nuevo y amplio grupo de personas.

Se conoce como \emph{Información Geográfica Voluntaria o Participativa} (en inglés Volunteered Geographical Information, VGI) al uso de Internet para crear, gestionar y difundir información geográfica aportada voluntariamente por usuarios de la propia red. El conjunto de herramientas y técnicas que emplean esos usuarios para aportar su información conforma lo que se ha dado en llamar \textbf{neogeografía}. La comparación entre proyectos de creación de VGI y la bien conocida Wikipedia sirve perfectamente para ilustrar qué es lo que entendemos por VGI y neogeografía, ya que lal VGI es el resultado de aplicar los conceptos de la \textbf{Web 2.0} al ámbito de la información geográfica. 

En el caso particular de esta última, la neogeografía ha supuesto un profundo cambio en algunas de las ideas básicas de la cartografía, modificando asimismo la concepción tradicional de la información geográfica, sus características o el papel que esta venía desempeñando en muchos ámbitos (o incluso dándole un papel en campos donde con anterioridad el uso de información geográfica era escaso). Algunas de las ideas principales sobre la neogeografía son las siguientes:

\begin{itemize}
	\item \textbf{Popularización y democratización}. La producción cartográfica ha estado siempre en manos de gobiernos u organismos, y en muchas ocasiones fuertemente censurada debido a su elevado valor estratégico. Con la VGI, la creación de información geográfica se democratiza y se convierte en un proceso participativo libre y sin restricciones.  Se invierte el esquema <<hacia abajo>> de producción y uso de información geográfica.
	\item Los ciudadanos se convierten en \textbf{sensores} y tienen mayor consciencia de su realidad geo--espacial.
	\item Se elimina parte del <<misticismo>> de la producción de información geográfica	
\end{itemize}


la neogeografía es en la actualidad un fenómeno que no debe dejarse de lado, ya que los proyectos que aglutina se están convirtiendo paulatinamente en proveedores fundamentales de datos cuya calidad en muchos casos es excelente.

El proyecto de VGI de mayor relevancia es \textbf{OpenStreetMap} (OSM), un <<proyecto colaborativo para crear mapas libres y editables>>.



\pagestyle{empty}